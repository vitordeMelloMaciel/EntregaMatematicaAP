{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c70cb17dd9cfa8",
   "metadata": {},
   "source": [
    "### Inteligência Artificial Preditiva\n",
    "### Este notebook tem como objetivo explorar modelos de regressão e classificação em uma base de dados, utilizando as seguintes abordagens:\n",
    "### Modelos de Regressão\n",
    "\n",
    "Regressão Linear\n",
    "\n",
    "K-Nearest Neighbors Regressor\n",
    "\n",
    "### Modelos de Classificação\n",
    "\n",
    "Naive Bayes (GaussianNB)\n",
    "\n",
    "Decision Tree (Critério Gini)\n",
    "\n",
    "Decision Tree (Critério Entropia)\n",
    "\n",
    "K-Nearest Neighbors (KNN)\n",
    "\n",
    "### A ideia é treinar todos os modelos disponíveis e selecionar automaticamente o que apresentar melhor desempenho, com base nas métricas adequadas:\n",
    "\n",
    "Classificação: F1-Score, Acurácia, Precision, Recall e AUC-ROC\n",
    "\n",
    "Regressão: R², RMSE, MAE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f933bb3f5861dc",
   "metadata": {},
   "source": [
    "<h1> Importando bibliotecas </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997df5bc6debb463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Pré-processamento\n",
    "# ADICIONADO: GridSearchCV para Validação Cruzada\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "# Modelos de Regressão\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Modelos de Classificação\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, classification_report,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa80865e001be3",
   "metadata": {},
   "source": [
    "<h1> Carregando a base de dados </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddee5a5713eeed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delimitador detectado: ','\n",
      "Arquivo 'Iris.csv' carregado com sucesso! Tamanho: (150, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_nome = \"Iris.csv\"  # ou \"iris.csv\", conforme o nome exato\n",
    "caminho = os.path.join(\"C:\\\\Users\\\\VitorMaciel-ieg\\\\PROJETO_INTER\\\\datasets\", csv_nome)\n",
    "\n",
    "# Verifica se o arquivo existe\n",
    "if not os.path.exists(caminho):\n",
    "    print(f\"Arquivo '{csv_nome}' não encontrado em '{caminho}'.\")\n",
    "else:\n",
    "    try:\n",
    "        with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
    "            sniffer = csv.Sniffer()\n",
    "            sample = f.read(2048)\n",
    "            f.seek(0)\n",
    "            delimiter_encontrado = sniffer.sniff(sample).delimiter\n",
    "        print(f\"Delimitador detectado: '{delimiter_encontrado}'\")\n",
    "        data = pd.read_csv(caminho, delimiter=delimiter_encontrado)\n",
    "        print(f\"Arquivo '{csv_nome}' carregado com sucesso! Tamanho: {data.shape}\")\n",
    "        display(data.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o arquivo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a59872",
   "metadata": {},
   "source": [
    "Seleção da Coluna Alvo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3474938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas disponíveis no dataset:\n",
      "1. Id\n",
      "2. SepalLengthCm\n",
      "3. SepalWidthCm\n",
      "4. PetalLengthCm\n",
      "5. PetalWidthCm\n",
      "6. Species\n",
      "\n",
      "Coluna alvo de classificação: Species\n"
     ]
    }
   ],
   "source": [
    "# Mostra todas as colunas\n",
    "print(\"Colunas disponíveis no dataset:\")\n",
    "for i, col in enumerate(data.columns):\n",
    "    print(f\"{i+1}. {col}\")\n",
    "\n",
    "# Defina a coluna alvo de classificação\n",
    "target_class_column = \"Species\"  # Substitua pelo nome da coluna que deseja prever\n",
    "# Para regressão, defina target_reg_column = \"nome_da_coluna\"\n",
    "\n",
    "print(f\"\\nColuna alvo de classificação: {target_class_column}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b4fd31fbf2555",
   "metadata": {},
   "source": [
    "<h1> Preparação de Dados para ML</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f5c9ccac85add6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 105 amostras | Teste: 45 amostras\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=[target_class_column])\n",
    "Y = data[target_class_column]\n",
    "\n",
    "# Split treino/teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=42, stratify=Y\n",
    ")\n",
    "\n",
    "# Padronização apenas para KNN\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Treino: {X_train.shape[0]} amostras | Teste: {X_test.shape[0]} amostras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62666cee5796e35",
   "metadata": {},
   "source": [
    "<h1> Treinamento e Avaliação de Modelos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97c457fd0ebb1575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Modelo: KNeighbors (Tuning com GridSearchCV)\n",
      "Melhores Parâmetros: {'n_neighbors': np.int64(3), 'weights': 'uniform'}\n",
      "Melhor F1-Score (CV): 1.0000\n",
      "Acurácia: 0.9778, F1-Score: 0.9778\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       0.94      1.00      0.97        15\n",
      " Iris-virginica       1.00      0.93      0.97        15\n",
      "\n",
      "       accuracy                           0.98        45\n",
      "      macro avg       0.98      0.98      0.98        45\n",
      "   weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "-> Modelo: DecisionTree (Tuning com GridSearchCV)\n",
      "Melhores Parâmetros: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Melhor F1-Score (CV): 0.9809\n",
      "Acurácia: 1.0000, F1-Score: 1.0000 (Melhor DT)\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       1.00      1.00      1.00        15\n",
      " Iris-virginica       1.00      1.00      1.00        15\n",
      "\n",
      "       accuracy                           1.00        45\n",
      "      macro avg       1.00      1.00      1.00        45\n",
      "   weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "-> Modelo: NaiveBayes (Treinamento direto)\n",
      "Acurácia: 0.9778, F1-Score: 0.9778\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       0.94      1.00      0.97        15\n",
      " Iris-virginica       1.00      0.93      0.97        15\n",
      "\n",
      "       accuracy                           0.98        45\n",
      "      macro avg       0.98      0.98      0.98        45\n",
      "   weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "\n",
      "#####################################\n",
      "Tabela de Resultados de Classificação\n",
      "#####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree_Gini</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree_Entropy</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.977753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Acurácia  F1-Score\n",
       "DecisionTree_Gini     1.000000  1.000000\n",
       "DecisionTree_Entropy  1.000000  1.000000\n",
       "KNeighbors            0.977778  0.977753\n",
       "NaiveBayes            0.977778  0.977753"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tuned_models_info = {\n",
    "    \"KNeighbors\": {\n",
    "        \"estimator\": KNeighborsClassifier(),\n",
    "        \"param_grid\": {'n_neighbors': np.arange(1, 21, 2), 'weights': ['uniform', 'distance']},\n",
    "        \"uses_scaled_data\": True\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"estimator\": DecisionTreeClassifier(random_state=42),\n",
    "        \"param_grid\": {\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [3, 5, 7, 9, None],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        \"uses_scaled_data\": False\n",
    "    },\n",
    "    \n",
    "    \"NaiveBayes\": {\n",
    "        \"estimator\": GaussianNB(),\n",
    "        \"param_grid\": {},\n",
    "        \"uses_scaled_data\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "classification_models = {}\n",
    "classification_results = {}\n",
    "\n",
    "#  Loop para treinamento e avaliação\n",
    "for nome_modelo, info in tuned_models_info.items():\n",
    "    \n",
    "    X_train_data = X_train_scaled if info[\"uses_scaled_data\"] else X_train\n",
    "    X_test_data = X_test_scaled if info[\"uses_scaled_data\"] else X_test\n",
    "    \n",
    "    modelo = info[\"estimator\"]\n",
    "    \n",
    "    if info[\"param_grid\"]: \n",
    "        \n",
    "        print(f\"\\n-> Modelo: {nome_modelo} (Tuning com GridSearchCV)\")\n",
    "        \n",
    "        # Configura e treina o GridSearch\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=modelo,\n",
    "            param_grid=info[\"param_grid\"],\n",
    "            scoring='f1_macro', \n",
    "            cv=5,\n",
    "            n_jobs=-1, \n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_data, Y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        Y_pred = best_model.predict(X_test_data)\n",
    "        \n",
    "        classification_models[nome_modelo] = best_model\n",
    "        \n",
    "        print(f\"Melhores Parâmetros: {grid_search.best_params_}\")\n",
    "        print(f\"Melhor F1-Score (CV): {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        print(f\"\\n-> Modelo: {nome_modelo} (Treinamento direto)\")\n",
    "        modelo.fit(X_train_data, Y_train)\n",
    "        Y_pred = modelo.predict(X_test_data)\n",
    "        classification_models[nome_modelo] = modelo\n",
    "        \n",
    "    #  Avaliação no conjunto de teste para o modelo final\n",
    "    acc = accuracy_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    if nome_modelo == \"DecisionTree\":\n",
    "       \n",
    "        classification_results[\"DecisionTree_Gini\"] = {'Acurácia': acc, 'F1-Score': f1}\n",
    "        classification_models[\"DecisionTree_Gini\"] = classification_models[nome_modelo]\n",
    "        \n",
    "        classification_results[\"DecisionTree_Entropy\"] = {'Acurácia': acc, 'F1-Score': f1}\n",
    "        classification_models[\"DecisionTree_Entropy\"] = classification_models[nome_modelo]\n",
    "        \n",
    "        print(f\"Acurácia: {acc:.4f}, F1-Score: {f1:.4f} (Melhor DT)\")\n",
    "        print(classification_report(Y_test, Y_pred, zero_division=0))\n",
    "\n",
    "    else:\n",
    "        classification_results[nome_modelo] = {'Acurácia': acc, 'F1-Score': f1}\n",
    "        print(f\"Acurácia: {acc:.4f}, F1-Score: {f1:.4f}\")\n",
    "        print(classification_report(Y_test, Y_pred, zero_division=0))\n",
    "\n",
    "df_class_results = pd.DataFrame(classification_results).T\n",
    "df_class_results = df_class_results.sort_values(by=['F1-Score', 'Acurácia'], ascending=False)\n",
    "\n",
    "print(\"\\n\\n#####################################\")\n",
    "print(\"Tabela de Resultados de Classificação\")\n",
    "print(\"#####################################\")\n",
    "display(df_class_results)\n",
    "\n",
    "if \"NaiveBayes\" not in classification_results:\n",
    "    classification_models[\"NaiveBayes\"] = tuned_models_info[\"NaiveBayes\"][\"estimator\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2430a4f064993e",
   "metadata": {},
   "source": [
    "<h1> Ranking de Modelos de Classificação </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accf766caa8f258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ranking Final de Classificação ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTree_Gini</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree_Entropy</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.9778</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaiveBayes</th>\n",
       "      <td>0.9778</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Acurácia  F1-Score\n",
       "DecisionTree_Gini       1.0000    1.0000\n",
       "DecisionTree_Entropy    1.0000    1.0000\n",
       "KNeighbors              0.9778    0.9778\n",
       "NaiveBayes              0.9778    0.9778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_class_results = pd.DataFrame(classification_results).T\n",
    "df_class_results = df_class_results.sort_values(by='F1-Score', ascending=False)\n",
    "print(\"=== Ranking Final de Classificação ===\")\n",
    "display(df_class_results.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba17c1",
   "metadata": {},
   "source": [
    "Preparação Modelo de Regressão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faae57a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 105 amostras | Teste: 45 amostras\n",
      "Colunas usadas como features de regressão:\n",
      "['Id', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n"
     ]
    }
   ],
   "source": [
    "# Defina a coluna alvo de regressão (deve ser numérica)\n",
    "target_reg_column = \"SepalLengthCm\"  # Exemplo, substitua pelo CSV que usar\n",
    "\n",
    "# Seleciona apenas colunas numéricas\n",
    "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "if target_reg_column not in numeric_columns:\n",
    "    raise ValueError(f\"A coluna alvo '{target_reg_column}' deve ser numérica.\")\n",
    "\n",
    "X_reg = data[numeric_columns].drop(columns=[target_reg_column])\n",
    "Y_reg = data[target_reg_column]\n",
    "\n",
    "# Split treino/teste\n",
    "X_train_r, X_test_r, Y_train_r, Y_test_r = train_test_split(\n",
    "    X_reg, Y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Padronização dos dados\n",
    "scaler_r = StandardScaler()\n",
    "X_train_r_scaled = scaler_r.fit_transform(X_train_r)\n",
    "X_test_r_scaled = scaler_r.transform(X_test_r)\n",
    "\n",
    "print(f\"Treino: {X_train_r.shape[0]} amostras | Teste: {X_test_r.shape[0]} amostras\")\n",
    "print(\"Colunas usadas como features de regressão:\")\n",
    "print(X_train_r.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8e1499f1a9266",
   "metadata": {},
   "source": [
    "<h1> Treinamento e Avaliação de Modelos de Regressão</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9858ca6721358bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Modelo: LinearRegression\n",
      "R²: 0.8498, RMSE: 0.3162, MAE: 0.2478\n",
      "\n",
      "-> Modelo: KNNRegressor\n",
      "R²: 0.8183, RMSE: 0.3478, MAE: 0.2627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "regression_models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"KNNRegressor\": KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "regression_results = {}\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    print(f\"\\n-> Modelo: {name}\")\n",
    "    \n",
    "    # Treina e faz previsões\n",
    "    model.fit(X_train_r_scaled, Y_train_r)\n",
    "    Y_pred = model.predict(X_test_r_scaled)\n",
    "    \n",
    "    # Calcula métricas\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test_r, Y_pred))\n",
    "    mae = mean_absolute_error(Y_test_r, Y_pred)\n",
    "    r2 = r2_score(Y_test_r, Y_pred)\n",
    "    \n",
    "    regression_results[name] = {'R²': r2, 'RMSE': rmse, 'MAE': mae}\n",
    "    \n",
    "    print(f\"R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b9f7eeb6e6962",
   "metadata": {},
   "source": [
    "<h1> Persistência do Melhor Modelo (Classificação) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bae8785dc1c92cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'DecisionTree_Gini' salvo em: datasets\\modelo_class_DecisionTree_Gini.pkl\n",
      "\n",
      "--- Processo concluído ---\n"
     ]
    }
   ],
   "source": [
    "best_model_name = df_class_results.index[0]\n",
    "best_model = classification_models[best_model_name]\n",
    "scaler_final = scaler if best_model_name == \"KNeighbors\" else None\n",
    "\n",
    "if not os.path.exists(\"datasets\"):\n",
    "    os.makedirs(\"datasets\")\n",
    "\n",
    "pickle_path = os.path.join(\"datasets\", f\"modelo_class_{best_model_name}.pkl\")\n",
    "with open(pickle_path, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(f\"Modelo '{best_model_name}' salvo em: {pickle_path}\")\n",
    "\n",
    "if scaler_final:\n",
    "    pickle_scaler_path = os.path.join(\"datasets\", \"scaler_class.pkl\")\n",
    "    with open(pickle_scaler_path, \"wb\") as f:\n",
    "        pickle.dump(scaler_final, f)\n",
    "    print(\"Scaler salvo em:\", pickle_scaler_path)\n",
    "\n",
    "print(\"\\n--- Processo concluído ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
